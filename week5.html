<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rapport 5</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark">
        <a class="navbar-brand" href="#">OOD-SLAM</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav">
                <li class="nav-item">
                    <a class="nav-link" href="index.html">Accueil</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="project-statement.html">Enoncé du projet</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="detailed-description.html">Description détaillée</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="development-plan.html">Plan de développement</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="progress-reports.html">Rapports d'avancement</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="final-report.html">Rapport final</a>
                </li>
            </ul>
        </div>
    </nav>
    <header class="bg-dark text-white text-center py-3">
        <h1>Rapport semaines 9-10</h1>
    </header>
    <div class="container mt-4">
        <h2>Rapport semaines 9-10</h2>
        <p style="text-align: justify;">
            Nous sommes actuellement dans la phase de recherche et d'expérimentation du projet. J'ai commencé par me familiariser avec l'environnement d'exécution. Puisque nous voulons entraîner un réseau de neurones artificiel avec de nombreux paramètres, il est inefficace de le faire fonctionner localement sur un CPU. Heureusement, le laboratoire dispose d'une solution pour cette problématique : nous avons accès à des ressources de calcul haute performance fournies par Compute Canada. Pour utiliser ces ressources, il est nécessaire de créer une image Singularity contenant le programme et toutes les dépendances nécessaires. Ainsi, durant la première semaine, je me suis familiarisé avec les procédures pour entraîner un modèle sur les clusters de Compute Canada (suivi d'un tutoriel et lecture sur Singularity et Docker).
        </p>
        
        <p style="text-align: justify;">
            Après m'être familiarisé avec le workflow, j'ai envoyé un premier modèle CNN sur un cluster pour qu'il soit entraîné. Nous avons choisi d'utiliser un modèle CNN préentraîné, AlexNet, très populaire dans la classification d'images. AlexNet a été entraîné sur des millions d'images du dataset ImageNet, ce qui lui permet de capturer des caractéristiques visuelles très diverses et complexes. Cette capacité à reconnaître et à extraire des caractéristiques pertinentes est très intéressante pour nous, car notre dataset est relativement petit en comparaison. En utilisant un modèle préentraîné, nous espérons tirer parti de ces caractéristiques déjà apprises et transférer cet apprentissage à notre problème spécifique de localisation et de cartographie simultanées (SLAM).
        </p>
        
        <p style="text-align: justify;">
            Ensuite, j'ai envoyé le même modèle avec des modifications concernant les fonctions de perte. Le premier modèle était un modèle de régression, donc nous avons modifié la dernière couche d'AlexNet, initialement une couche de classification, en une couche linéaire de régression avec une perte aux moindres carrés. Cependant, après avoir discuté avec mon superviseur, nous avons conclu que les tâches de classification sont généralement plus faciles à apprendre pour les réseaux de neurones. Nous avons donc décidé de discrétiser nos étiquettes d'entraînement (les erreurs de localisation par image) en utilisant la méthode des quantiles. Le deuxième modèle était donc également basé sur AlexNet mais fonctionnait maintenant comme un classifieur avec la fonction de perte d'entropie croisée.
        </p>
        
        <p style="text-align: justify;">
            Finalement, le troisième modèle envoyé était aussi un classifieur AlexNet mais cette fois-ci avec une fonction de perte EMD. Cette dernière peut incorporer une notion de distance et d'ordre entre les classes. Notre raisonnement est que, puisque nos classes sont des quantiles, prédire le quantile 5 au lieu du quantile 1 est plus grave que prédire le quantile 2, et nous voulons refléter ceci dans la perte. Pour le moment, nous en sommes là et attendons les résultats et les visualisations (nous utilisons le framework wandb pour la visualisation) pour discuter des résultats et planifier les prochaines expérimentations.
        </p>        
    </div>
    <footer class="footer bg-dark text-white text-center py-3">
        <p>&copy; 2024 Mon Projet de Stage de Recherche</p>
    </footer>
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.5.4/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
    <script src="script.js"></script>
</body>
</html>
